{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn.model_selection.KFold\n",
    "- class sklearn.model_selection.KFold(n_splits=5, *, shuffle=False, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "kf = KFold(n_splits=7)\n",
    "val_list = []\n",
    "for train_set, val_set in kf.split(X):\n",
    "    X_train, X_val = X[train_set], X[val_set]\n",
    "    y_train, y_val = y[train_set], y[val_set]\n",
    "    dt_clf = DecisionTreeClassifier()\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, pred)\n",
    "    val_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.945578231292517"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(val_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn.model_selection.StratifiedKFold\n",
    "- class sklearn.model_selection.StratifiedKFold(n_splits=5, *, shuffle=False, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "val_list = []\n",
    "for train_set, val_set in skf.split(X,y):\n",
    "    print(y[val_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-폴드 교차 검증 (K-Fold Cross Validation):\n",
    "\n",
    "K-폴드 교차 검증은 데이터를 K개의 서브셋(폴드)으로 나눈 다음, 각 폴드를 돌아가면서 훈련과 검증에 사용합니다.\n",
    "다음과 같은 단계로 진행됩니다:\n",
    "데이터를 K개의 폴드로 나눕니다.\n",
    "첫 번째 폴드를 검증 세트로 사용하고 나머지 K-1개의 폴드를 훈련 세트로 사용하여 모델을 훈련합니다.\n",
    "모델의 성능을 검증 세트에서 평가합니다.\n",
    "위 단계를 K번 반복하여 각 폴드에 대한 검증 성능을 평균하여 최종 성능을 얻습니다.\n",
    "이 방법을 통해 모델의 일반화 성능을 더 정확하게 예측할 수 있습니다. 특히 데이터가 적은 경우에 유용합니다.\n",
    "\n",
    "##### Stratified K-Fold Cross Validation은 클래스 간의 분포가 불균형한 경우에 사용되는 교차 검증 기법입니다. 기본적인 K-Fold Cross Validation과 비슷하지만, 각 폴드 내의 클래스 비율이 전체 데이터셋과 동일하도록 유지됩니다. 이것은 모델을 훈련할 때 각 폴드에서 모든 클래스가 충분히 대표되도록 보장합니다.\n",
    "\n",
    "Stratified K-Fold Cross Validation은 다음과 같은 단계로 수행됩니다:\n",
    "\n",
    "1. 데이터를 K개의 폴드로 나눕니다.\n",
    "2. 각 폴드 내에서 클래스 비율을 유지하도록 보장합니다.\n",
    "3. 한 폴드를 검증 세트로 사용하고, 나머지 K-1개의 폴드를 훈련 세트로 사용하여 모델을 훈련합니다.\n",
    "4. 모델의 성능을 검증 세트에서 평가합니다.\n",
    "5. 위 단계를 K번 반복하여 각 폴드에 대한 검증 성능을 평균하여 최종 성능을 얻습니다.\n",
    "\n",
    "Stratified K-Fold Cross Validation은 주로 클래스 불균형 문제를 해결하기 위해 사용됩니다. 클래스 불균형이 있는 경우에는 모든 클래스에 대한 충분한 샘플이 모델 훈련 및 검증에 사용되어야 하며, 이를 통해 모델이 각 클래스를 잘 학습하고 일반화할 수 있습니다.\n",
    "\n",
    "예를 들어, 이진 분류 문제에서 하나의 클래스가 다른 클래스보다 훨씬 더 많은 샘플을 가지고 있는 경우, 일반적인 K-Fold Cross Validation을 사용하면 클래스 간의 샘플 비율이 각 폴드에서 달라질 수 있습니다. 그러나 Stratified K-Fold Cross Validation을 사용하면 각 폴드에서 클래스 간의 샘플 비율이 유지되므로 모델의 성능을 더 정확하게 평가할 수 있습니다.\n",
    "\n",
    "#### 그리드 서치 교차 검증 (Grid Search CV):\n",
    "\n",
    "그리드 서치 교차 검증은 모델에 사용되는 하이퍼파라미터들의 가능한 조합을 지정한 후, 이들 조합 중에서 최적의 조합을 선택하는 기법입니다.\n",
    "다음과 같은 단계로 진행됩니다:\n",
    "탐색할 하이퍼파라미터들과 그들의 후보값들을 지정합니다.\n",
    "모든 가능한 하이퍼파라미터 조합을 만들기 위해 그리드를 구성합니다.\n",
    "각 조합에 대해 K-폴드 교차 검증을 실행하여 모델의 성능을 측정합니다.\n",
    "성능이 가장 우수한 하이퍼파라미터 조합을 선택합니다.\n",
    "이 방법을 통해 최적의 하이퍼파라미터 조합을 찾아 모델의 성능을 최대화할 수 있습니다.\n",
    "이러한 기술들은 과적합(overfitting)을 방지하고 모델의 일반화 성능을 높이는 데 도움을 줍니다. 또한 모델의 성능을 개선하기 위해 실험할 때 유용하게 활용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
