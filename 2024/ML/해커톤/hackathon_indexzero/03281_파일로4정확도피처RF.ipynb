{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'cp949' codec can't decode byte 0x9c in position 8: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score\n\u001b[1;32m---> 15\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m하이닉스 power1_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcp949\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 등락률을 기준으로 다음 날 등락률 계산 후 target 생성\u001b[39;00m\n\u001b[0;32m     17\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnext_day_return\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m종가\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m종가\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m/\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m종가\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1680\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:550\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:639\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:2021\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'cp949' codec can't decode byte 0x9c in position 8: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "from pykrx import stock\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "df = pd.read_csv(\"하이닉스 power1_data.csv\", thousands=',', encoding = 'cp949')\n",
    "# 등락률을 기준으로 다음 날 등락률 계산 후 target 생성\n",
    "df['next_day_return'] = (df['종가'].shift(-1) - df['종가'])/ df['종가'] *100\n",
    "df['target'] = df['next_day_return'].apply(lambda x: 1 if x > 0.25 else -1)\n",
    "df.dropna(inplace=True)  # 마지막 행 삭제\n",
    "\n",
    "first_column_name = df.columns[0]\n",
    "\n",
    "#df=df.iloc[-300:,:]\n",
    "X = df.drop(['날짜','target','next_day_return'], axis=1) \n",
    "y = df['target']\n",
    "\n",
    "\n",
    "# Calculating correlations for Forward Selection\n",
    "correlations = X.corrwith(y).abs().sort_values(ascending=False).reset_index()\n",
    "correlations.columns = ['Feature', 'Correlation']\n",
    "\n",
    "#Performing T-tests\n",
    "t_tests = {column: ttest_ind(X[column][y == 1], X[column][y == -1], nan_policy='omit') for column in X.columns}\n",
    "t_tests_sorted = sorted(t_tests.items(), key=lambda x: x[1].pvalue)\n",
    "t_tests_df = pd.DataFrame(t_tests_sorted, columns=['Feature', 'T-test'])\n",
    "t_tests_df['T-test'] = t_tests_df['T-test'].apply(lambda x: x.pvalue)  # Only keep p-value for simplicity\n",
    "\n",
    "# Lasso and Ridge regression\n",
    "lasso = LassoCV().fit(X, y)\n",
    "ridge = RidgeCV().fit(X, y)\n",
    "\n",
    "lasso_importance = np.abs(lasso.coef_)\n",
    "ridge_importance = np.abs(ridge.coef_)\n",
    "\n",
    "features_lasso_sorted = sorted(zip(X.columns, lasso_importance), key=lambda x: x[1], reverse=True)\n",
    "features_ridge_sorted = sorted(zip(X.columns, ridge_importance), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "features_lasso_df = pd.DataFrame(features_lasso_sorted, columns=['Feature', 'Lasso Importance'])\n",
    "features_ridge_df = pd.DataFrame(features_ridge_sorted, columns=['Feature', 'Ridge Importance'])\n",
    "\n",
    "# Random Forest for feature importance\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "\n",
    "features_rf_sorted = sorted(zip(X.columns, rf.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "features_rf_df = pd.DataFrame(features_rf_sorted, columns=['Feature', 'RF Importance'])\n",
    "\n",
    "# Combining all the data into a single dataframe without merging by feature\n",
    "final_df = pd.concat([correlations, t_tests_df.drop('Feature', axis=1), features_lasso_df.drop('Feature', axis=1), \n",
    "                      features_ridge_df.drop('Feature', axis=1), features_rf_df.drop('Feature', axis=1)], axis=1)\n",
    "\n",
    "# 상관관계가 가장 높은 상위 8개의 피처를 선정\n",
    "top_8_features = features_rf_sorted[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('시가', 0.4207289533567656),\n",
       " ('종가', 0.40666037818696776),\n",
       " ('MACD_Binary', 0.035399409348712586),\n",
       " ('이평 비교', 0.03189605382785128),\n",
       " ('RSI50이상', 0.027423781437379134),\n",
       " ('MACD비교', 0.021598381306592602),\n",
       " ('MACD_minus_Signal_Binary', 0.02118021067908168)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_8_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykrx import stock\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "df = pd.read_csv(\"하이닉스 power1_data.csv\", thousands=',', encoding='utf-8')\n",
    "# 등락률을 기준으로 다음 날 등락률 계산 후 target 생성\n",
    "df['next_day_return'] = (df['종가'].shift(-1) - df['종가'])/ df['종가'] *100\n",
    "df['target'] = df['next_day_return'].apply(lambda x: 2 if x > 0.25 else 1)\n",
    "df.dropna(inplace=True)  # 마지막 행 삭제\n",
    "\n",
    "first_column_name = df.columns[0]\n",
    "\n",
    "#df=df.iloc[-300:,:]\n",
    "X = df.drop(['날짜','target','next_day_return'], axis=1) \n",
    "y = df['target']\n",
    "\n",
    "\n",
    "# Random Forest for feature importance\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "\n",
    "features_rf_sorted = sorted(zip(X.columns, rf.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "features_rf_df = pd.DataFrame(features_rf_sorted, columns=['Feature', 'RF Importance'])\n",
    "\n",
    "# 상관관계가 가장 높은 상위 8개의 피처를 선정\n",
    "top_8_features = [feature for feature, importance in features_rf_sorted[:7]]\n",
    "\n",
    "# X와 y 정의 (df2와 이전 코드에서의 처리 과정을 바탕으로)dp\n",
    "X_top8 = X[top_8_features]\n",
    "y = df['target']  # y 값을 0과 1로 조정\n",
    "\n",
    "# # 데이터를 학습 세트와 테스트 세트로 분할\n",
    "# # Define y as befor\n",
    "# y = df['target']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_top8, y, test_size=0.25, random_state=66)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['고가_대비_종가_등락률',\n",
       " '[일]연기금 등_순매수',\n",
       " '거래량_등락률',\n",
       " '[일]사모펀드_순매수',\n",
       " '[일]기타법인_순매수',\n",
       " '[일]투신_순매수',\n",
       " '[일]은행_순매수']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_8_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.548438</td>\n",
       "      <td>0.688163</td>\n",
       "      <td>0.513920</td>\n",
       "      <td>0.383547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.500565</td>\n",
       "      <td>0.500142</td>\n",
       "      <td>0.399249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.509375</td>\n",
       "      <td>0.503519</td>\n",
       "      <td>0.503441</td>\n",
       "      <td>0.502357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.497627</td>\n",
       "      <td>0.498002</td>\n",
       "      <td>0.483358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifer</td>\n",
       "      <td>0.529687</td>\n",
       "      <td>0.516622</td>\n",
       "      <td>0.513134</td>\n",
       "      <td>0.493531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Precision    Recall  F1_Score\n",
       "0                        SVC  0.548438   0.688163  0.513920  0.383547\n",
       "1         LogisticRegression  0.531250   0.500565  0.500142  0.399249\n",
       "2     DecisionTreeClassifier  0.509375   0.503519  0.503441  0.502357\n",
       "3     RandomForestClassifier  0.512500   0.497627  0.498002  0.483358\n",
       "4  GradientBoostingClassifer  0.529687   0.516622  0.513134  0.493531"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터를 학습 세트와 테스트 세트로 분할\n",
    "# Define y as before\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top8, y, test_size=0.26, random_state=7)\n",
    "\n",
    "\n",
    "# 모델 초기화\n",
    "models = {\n",
    "    'SVC': SVC(max_iter=10000,random_state=1),\n",
    "    'LogisticRegression': LogisticRegression(random_state = 1),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(random_state =1),\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state =1),\n",
    "    'GradientBoostingClassifer' : GradientBoostingClassifier(random_state=1)\n",
    "}\n",
    "\n",
    "# 점수를 저장할 딕셔너리\n",
    "scores = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1_Score': []\n",
    "}\n",
    "\n",
    "# 각 모델에 대해 학습 및 평가\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    scores['Model'].append(model_name)\n",
    "    scores['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    scores['Precision'].append(precision_score(y_test, y_pred, average='macro'))\n",
    "    scores['Recall'].append(recall_score(y_test, y_pred, average='macro'))\n",
    "    scores['F1_Score'].append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# 점수 딕셔너리를 데이터프레임으로 변환\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingClassifer</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.590949</td>\n",
       "      <td>0.579442</td>\n",
       "      <td>0.577058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Precision    Recall  F1_Score\n",
       "0  GradientBoostingClassifer  0.609756   0.590949  0.579442  0.577058"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터를 학습 세트와 테스트 세트로 분할\n",
    "# Define y as before\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top8, y, test_size=0.25, random_state=90)\n",
    "\n",
    "\n",
    "# 모델 초기화\n",
    "models = {\n",
    "    'GradientBoostingClassifer' : GradientBoostingClassifier(random_state=90)\n",
    "}\n",
    "\n",
    "# 점수를 저장할 딕셔너리\n",
    "scores = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1_Score': []\n",
    "}\n",
    "\n",
    "# 각 모델에 대해 학습 및 평가\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    scores['Model'].append(model_name)\n",
    "    scores['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    scores['Precision'].append(precision_score(y_test, y_pred, average='macro'))\n",
    "    scores['Recall'].append(recall_score(y_test, y_pred, average='macro'))\n",
    "    scores['F1_Score'].append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# 점수 딕셔너리를 데이터프레임으로 변환\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.59187</td>\n",
       "      <td>0.58106</td>\n",
       "      <td>0.581493</td>\n",
       "      <td>0.581237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  Precision    Recall  F1_Score\n",
       "0  DecisionTreeClassifier   0.59187    0.58106  0.581493  0.581237"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터를 학습 세트와 테스트 세트로 분할\n",
    "# Define y as before\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top8, y, test_size=0.25, random_state=90)\n",
    "\n",
    "\n",
    "# 모델 초기화\n",
    "models = {\n",
    "    'DecisionTreeClassifier' : DecisionTreeClassifier(random_state=90)\n",
    "}\n",
    "\n",
    "# 점수를 저장할 딕셔너리\n",
    "scores = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1_Score': []\n",
    "}\n",
    "\n",
    "# 각 모델에 대해 학습 및 평가\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    scores['Model'].append(model_name)\n",
    "    scores['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    scores['Precision'].append(precision_score(y_test, y_pred, average='macro'))\n",
    "    scores['Recall'].append(recall_score(y_test, y_pred, average='macro'))\n",
    "    scores['F1_Score'].append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# 점수 딕셔너리를 데이터프레임으로 변환\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>0.599204</td>\n",
       "      <td>0.591291</td>\n",
       "      <td>0.590607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  Precision    Recall  F1_Score\n",
       "0  RandomForestClassifier    0.6125   0.599204  0.591291  0.590607"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터를 학습 세트와 테스트 세트로 분할\n",
    "# Define y as before\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top8, y, test_size=0.26, random_state=18)\n",
    "\n",
    "\n",
    "# 모델 초기화\n",
    "models = {\n",
    "    'RandomForestClassifier' : RandomForestClassifier(random_state=18)\n",
    "}\n",
    "\n",
    "# 점수를 저장할 딕셔너리\n",
    "scores = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1_Score': []\n",
    "}\n",
    "\n",
    "# 각 모델에 대해 학습 및 평가\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    scores['Model'].append(model_name)\n",
    "    scores['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    scores['Precision'].append(precision_score(y_test, y_pred, average='macro'))\n",
    "    scores['Recall'].append(recall_score(y_test, y_pred, average='macro'))\n",
    "    scores['F1_Score'].append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# 점수 딕셔너리를 데이터프레임으로 변환\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.577236</td>\n",
       "      <td>0.676018</td>\n",
       "      <td>0.51035</td>\n",
       "      <td>0.389564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy  Precision   Recall  F1_Score\n",
       "0  LogisticRegression  0.577236   0.676018  0.51035  0.389564"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터를 학습 세트와 테스트 세트로 분할\n",
    "# Define y as before\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top8, y, test_size=0.25, random_state=55)\n",
    "\n",
    "\n",
    "# 모델 초기화\n",
    "models = {\n",
    "    'LogisticRegression' : LogisticRegression(random_state=55)\n",
    "}\n",
    "\n",
    "# 점수를 저장할 딕셔너리\n",
    "scores = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1_Score': []\n",
    "}\n",
    "\n",
    "# 각 모델에 대해 학습 및 평가\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    scores['Model'].append(model_name)\n",
    "    scores['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    scores['Precision'].append(precision_score(y_test, y_pred, average='macro'))\n",
    "    scores['Recall'].append(recall_score(y_test, y_pred, average='macro'))\n",
    "    scores['F1_Score'].append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# 점수 딕셔너리를 데이터프레임으로 변환\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>RF Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>고가_대비_종가_등락률</td>\n",
       "      <td>0.027854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[일]연기금 등_순매수</td>\n",
       "      <td>0.025828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[일]투신_순매수</td>\n",
       "      <td>0.025743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[일]기타법인_순매수</td>\n",
       "      <td>0.025155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[일]은행_순매수</td>\n",
       "      <td>0.024229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[일]사모펀드_순매수</td>\n",
       "      <td>0.024184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>거래량_등락률</td>\n",
       "      <td>0.022772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  RF Importance\n",
       "0  고가_대비_종가_등락률       0.027854\n",
       "1  [일]연기금 등_순매수       0.025828\n",
       "2     [일]투신_순매수       0.025743\n",
       "3   [일]기타법인_순매수       0.025155\n",
       "4     [일]은행_순매수       0.024229\n",
       "5   [일]사모펀드_순매수       0.024184\n",
       "6       거래량_등락률       0.022772"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_rf_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.131412245069214, tolerance: 0.04858921668362156\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06537523262574041, tolerance: 0.048392929806714086\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11951387975636862, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.923422784020829, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.452322567877331, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.522648600806463, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.796346962590235, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1189161475239757, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.5727385161724783, tolerance: 0.04843680732079309\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.300276590178271, tolerance: 0.04873055414336554\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.17102588618269, tolerance: 0.04873055414336554\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.17743480664205435, tolerance: 0.04873055414336554\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3332288516097037, tolerance: 0.04873055414336554\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.571816</td>\n",
       "      <td>0.524573</td>\n",
       "      <td>0.504664</td>\n",
       "      <td>0.408252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.571816</td>\n",
       "      <td>0.528148</td>\n",
       "      <td>0.506730</td>\n",
       "      <td>0.419534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.520325</td>\n",
       "      <td>0.515346</td>\n",
       "      <td>0.515623</td>\n",
       "      <td>0.514622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.543360</td>\n",
       "      <td>0.519152</td>\n",
       "      <td>0.517080</td>\n",
       "      <td>0.512030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifer</td>\n",
       "      <td>0.566396</td>\n",
       "      <td>0.544918</td>\n",
       "      <td>0.539606</td>\n",
       "      <td>0.534917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Precision    Recall  F1_Score\n",
       "0                        SVC  0.571816   0.524573  0.504664  0.408252\n",
       "1         LogisticRegression  0.571816   0.528148  0.506730  0.419534\n",
       "2     DecisionTreeClassifier  0.520325   0.515346  0.515623  0.514622\n",
       "3     RandomForestClassifier  0.543360   0.519152  0.517080  0.512030\n",
       "4  GradientBoostingClassifer  0.566396   0.544918  0.539606  0.534917"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pykrx import stock\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "df = pd.read_csv(\"하이닉스 power1_data.csv\", thousands=',', encoding='utf-8')\n",
    "# 등락률을 기준으로 다음 날 등락률 계산 후 target 생성\n",
    "df['next_day_return'] = (df['종가'].shift(-1) - df['종가'])/ df['종가'] *100\n",
    "df['target'] = df['next_day_return'].apply(lambda x: 2 if x > 0.25 else 1)\n",
    "df.dropna(inplace=True)  # 마지막 행 삭제\n",
    "\n",
    "first_column_name = df.columns[0]\n",
    "\n",
    "#df=df.iloc[-300:,:]\n",
    "X = df.drop(['날짜','target','next_day_return'], axis=1) \n",
    "y = df['target']\n",
    "\n",
    "\n",
    "# Calculating correlations for Forward Selection\n",
    "correlations = X.corrwith(y).abs().sort_values(ascending=False).reset_index()\n",
    "correlations.columns = ['Feature', 'Correlation']\n",
    "\n",
    "#Performing T-tests\n",
    "t_tests = {column: ttest_ind(X[column][y == 1], X[column][y == -1], nan_policy='omit') for column in X.columns}\n",
    "t_tests_sorted = sorted(t_tests.items(), key=lambda x: x[1].pvalue)\n",
    "t_tests_df = pd.DataFrame(t_tests_sorted, columns=['Feature', 'T-test'])\n",
    "t_tests_df['T-test'] = t_tests_df['T-test'].apply(lambda x: x.pvalue)  # Only keep p-value for simplicity\n",
    "\n",
    "# Lasso and Ridge regression\n",
    "lasso = LassoCV().fit(X, y)\n",
    "ridge = RidgeCV().fit(X, y)\n",
    "\n",
    "lasso_importance = np.abs(lasso.coef_)\n",
    "ridge_importance = np.abs(ridge.coef_)\n",
    "\n",
    "features_lasso_sorted = sorted(zip(X.columns, lasso_importance), key=lambda x: x[1], reverse=True)\n",
    "features_ridge_sorted = sorted(zip(X.columns, ridge_importance), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "features_lasso_df = pd.DataFrame(features_lasso_sorted, columns=['Feature', 'Lasso Importance'])\n",
    "features_ridge_df = pd.DataFrame(features_ridge_sorted, columns=['Feature', 'Ridge Importance'])\n",
    "\n",
    "# Random Forest for feature importance\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "\n",
    "features_rf_sorted = sorted(zip(X.columns, rf.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "features_rf_df = pd.DataFrame(features_rf_sorted, columns=['Feature', 'RF Importance'])\n",
    "\n",
    "# Combining all the data into a single dataframe without merging by feature\n",
    "final_df = pd.concat([correlations, t_tests_df.drop('Feature', axis=1), features_lasso_df.drop('Feature', axis=1), \n",
    "                      features_ridge_df.drop('Feature', axis=1), features_rf_df.drop('Feature', axis=1)], axis=1)\n",
    "\n",
    "# 상관관계가 가장 높은 상위 8개의 피처를 선정\n",
    "top_8_features = [feature for feature, importance in features_rf_sorted[:7]]\n",
    "\n",
    "# X와 y 정의 (df2와 이전 코드에서의 처리 과정을 바탕으로)dp\n",
    "X_top8 = X[top_8_features]\n",
    "y = df['target']  # y 값을 0과 1로 조정\n",
    "\n",
    "# 데이터를 학습 세트와 테스트 세트로 분할\n",
    "# Define y as before\n",
    "y = df['target']\n",
    "\n",
    "# Split the data into training and testing sets based on the specified index\n",
    "X_train = X_top8.iloc[:1720]  # Up to and including index 1719\n",
    "X_test = X_top8.iloc[1720:]   # From index 1720 to the end\n",
    "\n",
    "y_train = y.iloc[:1720]       # Corresponding y values for training\n",
    "y_test = y.iloc[1720:]        # Corresponding y values for testing\n",
    "\n",
    "# 모델 초기화\n",
    "models = {\n",
    "    'SVC': SVC(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'GradientBoostingClassifer' : GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# 점수를 저장할 딕셔너리\n",
    "scores = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1_Score': []\n",
    "}\n",
    "\n",
    "# 각 모델에 대해 학습 및 평가\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    scores['Model'].append(model_name)\n",
    "    scores['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    scores['Precision'].append(precision_score(y_test, y_pred, average='macro'))\n",
    "    scores['Recall'].append(recall_score(y_test, y_pred, average='macro'))\n",
    "    scores['F1_Score'].append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# 점수 딕셔너리를 데이터프레임으로 변환\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>RF Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>고가_대비_종가_등락률</td>\n",
       "      <td>0.028528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[일]투신_순매수</td>\n",
       "      <td>0.025609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[일]연기금 등_순매수</td>\n",
       "      <td>0.025388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[일]기타법인_순매수</td>\n",
       "      <td>0.023654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[일]사모펀드_순매수</td>\n",
       "      <td>0.023574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>거래량_등락률</td>\n",
       "      <td>0.022705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RSI_등락률</td>\n",
       "      <td>0.021196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  RF Importance\n",
       "0  고가_대비_종가_등락률       0.028528\n",
       "1     [일]투신_순매수       0.025609\n",
       "2  [일]연기금 등_순매수       0.025388\n",
       "3   [일]기타법인_순매수       0.023654\n",
       "4   [일]사모펀드_순매수       0.023574\n",
       "5       거래량_등락률       0.022705\n",
       "6       RSI_등락률       0.021196"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_rf_df.head(7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
