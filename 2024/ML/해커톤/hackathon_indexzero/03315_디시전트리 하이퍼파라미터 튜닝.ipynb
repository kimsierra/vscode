{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming the data preparation is similar to previous examples\n",
    "df = pd.read_csv(\"하이닉스 power (3).csv\", thousands=',', encoding='cp949')\n",
    "df['next_day_return'] = (df['종가'].shift(-1) - df['종가']) / df['종가'] * 100\n",
    "df['target'] = df['next_day_return'].apply(lambda x: 1 if x > 0.25 else 0)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop(['날짜', 'target', 'next_day_return'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "# Decision Tree Classifier Hyperparameters Grid\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 2, 4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_dt = GridSearchCV(DecisionTreeClassifier(random_state=1), param_grid_dt, refit=True, verbose=2, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best model\n",
    "print(\"Best parameters:\", grid_search_dt.best_params_)\n",
    "best_dt_model = grid_search_dt.best_estimator_\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred_dt = best_dt_model.predict(X_test)\n",
    "\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt, average='macro')\n",
    "recall_dt = recall_score(y_test, y_pred_dt, average='macro')\n",
    "f1_dt = f1_score(y_test, y_pred_dt, average='macro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "print(\"Precision:\", precision_dt)\n",
    "print(\"Recall:\", recall_dt)\n",
    "print(\"F1 Score:\", f1_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d637b71502146b2aaffdc45811fc163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  36 | elapsed:   48.4s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   51.8s finished\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 40\u001b[0m\n\u001b[0;32m     35\u001b[0m results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)(\n\u001b[0;32m     36\u001b[0m     delayed(evaluate_model)(params) \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mlist\u001b[39m(ParameterGrid(param_grid)))\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# 최적의 하이퍼파라미터 조합 찾기\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m best_score_idx \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39margmax(results)\n\u001b[0;32m     41\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ParameterGrid(param_grid))[best_score_idx]\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "df = pd.read_csv(\"하이닉스 power (3).csv\", thousands=',', encoding='cp949')\n",
    "df['next_day_return'] = (df['종가'].shift(-1) - df['종가']) / df['종가'] * 100\n",
    "df['target'] = df['next_day_return'].apply(lambda x: 1 if x > 0.25 else 0)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop(['날짜', 'target', 'next_day_return'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "# 결정 트리 모델을 위한 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# 사용자 정의 함수로 모델 학습 및 평가\n",
    "def evaluate_model(params):\n",
    "    model = DecisionTreeClassifier(**params, random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    return scores.mean()\n",
    "\n",
    "# 모든 하이퍼파라미터 조합에 대해 평가\n",
    "results = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(evaluate_model)(params) for params in tqdm(list(ParameterGrid(param_grid)))\n",
    ")\n",
    "\n",
    "# 최적의 하이퍼파라미터 조합 찾기\n",
    "best_score_idx = np.argmax(results)\n",
    "best_params = list(ParameterGrid(param_grid))[best_score_idx]\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best score: {results[best_score_idx]}\")\n",
    "\n",
    "# 최적의 모델로 테스트 데이터 예측\n",
    "best_model = DecisionTreeClassifier(**best_params, random_state=1)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 예측 결과에 대한 평가 지표 출력\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
