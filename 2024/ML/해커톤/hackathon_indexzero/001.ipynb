{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6698808845565054, tolerance: 0.04858921668362156\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.16642145181617707, tolerance: 0.048392929806714086\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11681455613887692, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.910843624224583, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.434017501527137, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.49949549543021, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.64935387370582, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.913421962448183, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.5727385161910092, tolerance: 0.04843680732079309\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.3048436542495097, tolerance: 0.04873055414336554\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.177602535398933, tolerance: 0.04873055414336554\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.17151233262632104, tolerance: 0.04873055414336554\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.33128037733729343, tolerance: 0.04873055414336554\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.582114</td>\n",
       "      <td>0.587113</td>\n",
       "      <td>0.514954</td>\n",
       "      <td>0.418806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.606504</td>\n",
       "      <td>0.594408</td>\n",
       "      <td>0.567194</td>\n",
       "      <td>0.551717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.541463</td>\n",
       "      <td>0.533805</td>\n",
       "      <td>0.534151</td>\n",
       "      <td>0.533770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.549593</td>\n",
       "      <td>0.525178</td>\n",
       "      <td>0.522047</td>\n",
       "      <td>0.516011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifer</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.538978</td>\n",
       "      <td>0.534421</td>\n",
       "      <td>0.529529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Precision    Recall  F1_Score\n",
       "0                        SVC  0.582114   0.587113  0.514954  0.418806\n",
       "1         LogisticRegression  0.606504   0.594408  0.567194  0.551717\n",
       "2     DecisionTreeClassifier  0.541463   0.533805  0.534151  0.533770\n",
       "3     RandomForestClassifier  0.549593   0.525178  0.522047  0.516011\n",
       "4  GradientBoostingClassifer  0.560976   0.538978  0.534421  0.529529"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pykrx import stock\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "df = pd.read_csv(\"하이닉스 power (3).csv\", thousands=',', encoding = 'cp949')\n",
    "# 등락률을 기준으로 다음 날 등락률 계산 후 target 생성\n",
    "df['next_day_return'] = (df['종가'].shift(-1) - df['종가'])/ df['종가'] *100\n",
    "df['target'] = df['next_day_return'].apply(lambda x: 2 if x > 0.25 else 1)\n",
    "df.dropna(inplace=True)  # 마지막 행 삭제\n",
    "\n",
    "first_column_name = df.columns[0]\n",
    "\n",
    "#df=df.iloc[-300:,:]\n",
    "X = df.drop(['날짜','target','next_day_return'], axis=1) \n",
    "y = df['target']\n",
    "\n",
    "\n",
    "# Calculating correlations for Forward Selection\n",
    "correlations = X.corrwith(y).abs().sort_values(ascending=False).reset_index()\n",
    "correlations.columns = ['Feature', 'Correlation']\n",
    "\n",
    "#Performing T-tests\n",
    "t_tests = {column: ttest_ind(X[column][y == 1], X[column][y == -1], nan_policy='omit') for column in X.columns}\n",
    "t_tests_sorted = sorted(t_tests.items(), key=lambda x: x[1].pvalue)\n",
    "t_tests_df = pd.DataFrame(t_tests_sorted, columns=['Feature', 'T-test'])\n",
    "t_tests_df['T-test'] = t_tests_df['T-test'].apply(lambda x: x.pvalue)  # Only keep p-value for simplicity\n",
    "\n",
    "# Lasso and Ridge regression\n",
    "lasso = LassoCV().fit(X, y)\n",
    "ridge = RidgeCV().fit(X, y)\n",
    "\n",
    "lasso_importance = np.abs(lasso.coef_)\n",
    "ridge_importance = np.abs(ridge.coef_)\n",
    "\n",
    "features_lasso_sorted = sorted(zip(X.columns, lasso_importance), key=lambda x: x[1], reverse=True)\n",
    "features_ridge_sorted = sorted(zip(X.columns, ridge_importance), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "features_lasso_df = pd.DataFrame(features_lasso_sorted, columns=['Feature', 'Lasso Importance'])\n",
    "features_ridge_df = pd.DataFrame(features_ridge_sorted, columns=['Feature', 'Ridge Importance'])\n",
    "\n",
    "# Random Forest for feature importance\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "\n",
    "features_rf_sorted = sorted(zip(X.columns, rf.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "features_rf_df = pd.DataFrame(features_rf_sorted, columns=['Feature', 'RF Importance'])\n",
    "\n",
    "# Combining all the data into a single dataframe without merging by feature\n",
    "final_df = pd.concat([correlations, t_tests_df.drop('Feature', axis=1), features_lasso_df.drop('Feature', axis=1), \n",
    "                      features_ridge_df.drop('Feature', axis=1), features_rf_df.drop('Feature', axis=1)], axis=1)\n",
    "\n",
    "# 상관관계가 가장 높은 상위 8개의 피처를 선정\n",
    "top_8_features = [feature for feature, importance in features_rf_sorted[:7]]\n",
    "\n",
    "# X와 y 정의 (df2와 이전 코드에서의 처리 과정을 바탕으로)dp\n",
    "X_top8 = X[top_8_features]\n",
    "y = df['target']  # y 값을 0과 1로 조정\n",
    "\n",
    "# 데이터를 학습 세트와 테스트 세트로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top8, y, test_size=0.25, random_state=66)\n",
    "\n",
    "# 모델 초기화\n",
    "models = {\n",
    "    'SVC': SVC(),\n",
    "    'LogisticRegression': LogisticRegression(random_state =1),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(random_),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'GradientBoostingClassifer' : GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# 점수를 저장할 딕셔너리\n",
    "scores = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1_Score': []\n",
    "}\n",
    "\n",
    "# 각 모델에 대해 학습 및 평가\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    scores['Model'].append(model_name)\n",
    "    scores['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    scores['Precision'].append(precision_score(y_test, y_pred, average='macro'))\n",
    "    scores['Recall'].append(recall_score(y_test, y_pred, average='macro'))\n",
    "    scores['F1_Score'].append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# 점수 딕셔너리를 데이터프레임으로 변환\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
