{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0d223e885c41a19f764ba2311ac089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Precision Scores:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Random_State  Precision\n",
      "0              1   0.609475\n",
      "1              2   0.609475\n",
      "2              3   0.609475\n",
      "3              4   0.609475\n",
      "4              5   0.609475\n",
      "5              6   0.609475\n",
      "6              7   0.609475\n",
      "7              8   0.609475\n",
      "8              9   0.609475\n",
      "9             10   0.609475\n",
      "10            11   0.609475\n",
      "11            12   0.609475\n",
      "12            13   0.609475\n",
      "13            14   0.609475\n",
      "14            15   0.609475\n",
      "15            16   0.609475\n",
      "16            17   0.609475\n",
      "17            18   0.609475\n",
      "18            19   0.609475\n",
      "19            20   0.609475\n",
      "20            21   0.609475\n",
      "21            22   0.609475\n",
      "22            23   0.609475\n",
      "23            24   0.609475\n",
      "24            25   0.609475\n",
      "25            26   0.609475\n",
      "26            27   0.609475\n",
      "27            28   0.609475\n",
      "28            29   0.609475\n",
      "29            30   0.609475\n",
      "30            31   0.609475\n",
      "31            32   0.609475\n",
      "32            33   0.609475\n",
      "33            34   0.609475\n",
      "34            35   0.609475\n",
      "35            36   0.609475\n",
      "36            37   0.609475\n",
      "37            38   0.609475\n",
      "38            39   0.609475\n",
      "39            40   0.609475\n",
      "40            41   0.609475\n",
      "41            42   0.609475\n",
      "42            43   0.609475\n",
      "43            44   0.609475\n",
      "44            45   0.609475\n",
      "45            46   0.609475\n",
      "46            47   0.609475\n",
      "47            48   0.609475\n",
      "48            49   0.609475\n",
      "49            50   0.609475\n",
      "50            51   0.609475\n",
      "51            52   0.609475\n",
      "52            53   0.609475\n",
      "53            54   0.609475\n",
      "54            55   0.609475\n",
      "55            56   0.609475\n",
      "56            57   0.609475\n",
      "57            58   0.609475\n",
      "58            59   0.609475\n",
      "59            60   0.609475\n",
      "60            61   0.609475\n",
      "61            62   0.609475\n",
      "62            63   0.609475\n",
      "63            64   0.609475\n",
      "64            65   0.609475\n",
      "65            66   0.609475\n",
      "66            67   0.609475\n",
      "67            68   0.609475\n",
      "68            69   0.609475\n",
      "69            70   0.609475\n",
      "70            71   0.609475\n",
      "71            72   0.609475\n",
      "72            73   0.609475\n",
      "73            74   0.609475\n",
      "74            75   0.609475\n",
      "75            76   0.609475\n",
      "76            77   0.609475\n",
      "77            78   0.609475\n",
      "78            79   0.609475\n",
      "79            80   0.609475\n",
      "80            81   0.609475\n",
      "81            82   0.609475\n",
      "82            83   0.609475\n",
      "83            84   0.609475\n",
      "84            85   0.609475\n",
      "85            86   0.609475\n",
      "86            87   0.609475\n",
      "87            88   0.609475\n",
      "88            89   0.609475\n",
      "89            90   0.609475\n",
      "90            91   0.609475\n",
      "91            92   0.609475\n",
      "92            93   0.609475\n",
      "93            94   0.609475\n",
      "94            95   0.609475\n",
      "95            96   0.609475\n",
      "96            97   0.609475\n",
      "97            98   0.609475\n",
      "98            99   0.609475\n",
      "99           100   0.609475\n",
      "Best Random State: 1.0, Highest Precision: 0.6095\n"
     ]
    }
   ],
   "source": [
    "from pykrx import stock\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "df = pd.read_csv(\"하이닉스 power1_data.csv\", thousands=',', encoding='utf-8')\n",
    "# 등락률을 기준으로 다음 날 등락률 계산 후 target 생성\n",
    "df['next_day_return'] = (df['종가'].shift(-1) - df['종가'])/ df['종가'] *100\n",
    "df['target'] = df['next_day_return'].apply(lambda x: 2 if x > 0.25 else 1)\n",
    "df.dropna(inplace=True)  # 마지막 행 삭제\n",
    "\n",
    "first_column_name = df.columns[0]\n",
    "\n",
    "#df=df.iloc[-300:,:]\n",
    "X = df.drop(['날짜','target','next_day_return'], axis=1) \n",
    "y = df['target']\n",
    "\n",
    "\n",
    "# Random Forest for feature importance\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "\n",
    "features_rf_sorted = sorted(zip(X.columns, rf.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "features_rf_df = pd.DataFrame(features_rf_sorted, columns=['Feature', 'RF Importance'])\n",
    "\n",
    "# 상관관계가 가장 높은 상위 8개의 피처를 선정\n",
    "top_8_features = [feature for feature, importance in features_rf_sorted[:7]]\n",
    "\n",
    "# X와 y 정의 (df2와 이전 코드에서의 처리 과정을 바탕으로)dp\n",
    "X_top8 = X[top_8_features]\n",
    "y = df['target']  # y 값을 0과 1로 조정\n",
    "\n",
    "# 데이터를 학습 세트와 테스트 세트로 분할\n",
    "# Define y as before\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top8, y, test_size=0.25, random_state=66)\n",
    "\n",
    "# # Split the data into training and testing sets based on the specified index\n",
    "# X_train = X_top8.iloc[:1720]  # Up to and including index 1719\n",
    "# X_test = X_top8.iloc[1720:]   # From index 1720 to the end\n",
    "\n",
    "# y_train = y.iloc[:1720]       # Corresponding y values for training\n",
    "# y_test = y.iloc[1720:]        # Corresponding y values for testing\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 정밀도 점수를 저장할 리스트 생성\n",
    "precision_results = []\n",
    "\n",
    "# tqdm을 사용하여 random_state에 대한 반복 실행\n",
    "for state in tqdm(range(1, 101), desc='Calculating Precision Scores'):\n",
    "    lr_model = LogisticRegression(max_iter=10000, random_state=state)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    y_pred = lr_model.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # 결과를 리스트에 추가\n",
    "    precision_results.append({'Random_State': state, 'Precision': precision})\n",
    "\n",
    "# 리스트를 DataFrame으로 변환\n",
    "precision_results_df = pd.DataFrame(precision_results)\n",
    "\n",
    "# 결과 출력\n",
    "print(precision_results_df)\n",
    "\n",
    "# 추가: 가장 높은 정밀도를 갖는 random_state 확인\n",
    "best_result = precision_results_df.loc[precision_results_df['Precision'].idxmax()]\n",
    "print(f\"Best Random State: {best_result['Random_State']}, Highest Precision: {best_result['Precision']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
