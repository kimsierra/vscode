{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.131412245069214, tolerance: 0.04858921668362156\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06537523262574041, tolerance: 0.048392929806714086\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11951387975636862, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.923422784020829, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.452322567877331, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.522648600806463, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.796346962590235, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1189161475239757, tolerance: 0.04847731434384537\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.5727385161724783, tolerance: 0.04843680732079309\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.300276590178271, tolerance: 0.04873055414336554\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.17102588618269, tolerance: 0.04873055414336554\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.17743480664205435, tolerance: 0.04873055414336554\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3332288516097037, tolerance: 0.04873055414336554\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ad6a59b0aa44be9411638cb73078d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Overall Progress:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model     DecisionTreeClassifier  GradientBoostingClassifer  \\\n",
      "Features                                                      \n",
      "5                       0.491256                   0.519150   \n",
      "6                       0.514940                   0.522631   \n",
      "7                       0.521710                   0.541052   \n",
      "8                       0.517741                   0.531478   \n",
      "9                       0.520794                   0.549975   \n",
      "10                      0.522738                   0.539414   \n",
      "11                      0.475951                   0.504514   \n",
      "12                      0.516532                   0.539004   \n",
      "13                      0.502489                   0.516104   \n",
      "14                      0.520018                   0.518932   \n",
      "15                      0.532872                   0.515085   \n",
      "\n",
      "Model     LogisticRegression  RandomForestClassifier       SVC  \n",
      "Features                                                        \n",
      "5                   0.517790                0.541183  0.569621  \n",
      "6                   0.582621                0.546946  0.560049  \n",
      "7                   0.540562                0.529216  0.560049  \n",
      "8                   0.523442                0.536121  0.560049  \n",
      "9                   0.525016                0.550279  0.512604  \n",
      "10                  0.518690                0.540629  0.538408  \n",
      "11                  0.506977                0.542686  0.538408  \n",
      "12                  0.508679                0.533813  0.538408  \n",
      "13                  0.506573                0.529813  0.538408  \n",
      "14                  0.508130                0.535494  0.538408  \n",
      "15                  0.518970                0.553086  0.538301  \n"
     ]
    }
   ],
   "source": [
    "from pykrx import stock\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"하이닉스 power1_data.csv\", thousands=',', encoding='utf-8')\n",
    "# 등락률을 기준으로 다음 날 등락률 계산 후 target 생성\n",
    "df['next_day_return'] = (df['종가'].shift(-1) - df['종가'])/ df['종가'] *100\n",
    "df['target'] = df['next_day_return'].apply(lambda x: 2 if x > 0.25 else 1)\n",
    "df.dropna(inplace=True)  # 마지막 행 삭제\n",
    "\n",
    "first_column_name = df.columns[0]\n",
    "\n",
    "#df=df.iloc[-300:,:]\n",
    "X = df.drop(['날짜','target','next_day_return'], axis=1) \n",
    "y = df['target']\n",
    "\n",
    "\n",
    "# Calculating correlations for Forward Selection\n",
    "correlations = X.corrwith(y).abs().sort_values(ascending=False).reset_index()\n",
    "correlations.columns = ['Feature', 'Correlation']\n",
    "\n",
    "#Performing T-tests\n",
    "t_tests = {column: ttest_ind(X[column][y == 1], X[column][y == -1], nan_policy='omit') for column in X.columns}\n",
    "t_tests_sorted = sorted(t_tests.items(), key=lambda x: x[1].pvalue)\n",
    "t_tests_df = pd.DataFrame(t_tests_sorted, columns=['Feature', 'T-test'])\n",
    "t_tests_df['T-test'] = t_tests_df['T-test'].apply(lambda x: x.pvalue)  # Only keep p-value for simplicity\n",
    "\n",
    "# Lasso and Ridge regression\n",
    "lasso = LassoCV().fit(X, y)\n",
    "ridge = RidgeCV().fit(X, y)\n",
    "\n",
    "lasso_importance = np.abs(lasso.coef_)\n",
    "ridge_importance = np.abs(ridge.coef_)\n",
    "\n",
    "features_lasso_sorted = sorted(zip(X.columns, lasso_importance), key=lambda x: x[1], reverse=True)\n",
    "features_ridge_sorted = sorted(zip(X.columns, ridge_importance), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "features_lasso_df = pd.DataFrame(features_lasso_sorted, columns=['Feature', 'Lasso Importance'])\n",
    "features_ridge_df = pd.DataFrame(features_ridge_sorted, columns=['Feature', 'Ridge Importance'])\n",
    "\n",
    "# Random Forest for feature importance\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "\n",
    "features_rf_sorted = sorted(zip(X.columns, rf.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "features_rf_df = pd.DataFrame(features_rf_sorted, columns=['Feature', 'RF Importance'])\n",
    "\n",
    "# Combining all the data into a single dataframe without merging by feature\n",
    "final_df = pd.concat([correlations, t_tests_df.drop('Feature', axis=1), features_lasso_df.drop('Feature', axis=1), \n",
    "                      features_ridge_df.drop('Feature', axis=1), features_rf_df.drop('Feature', axis=1)], axis=1)\n",
    "\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "results = []\n",
    "\n",
    "models = {\n",
    "    'SVC': SVC(random_state=1),\n",
    "    'LogisticRegression': LogisticRegression(random_state = 1),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(random_state =1),\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state =1),\n",
    "    'GradientBoostingClassifer' : GradientBoostingClassifier(random_state=1)\n",
    "}\n",
    "\n",
    "\n",
    "# 피처 중요도 기반 상위 피처 선택 및 평가 반복\n",
    "for i in tqdm(range(5, 16), desc='Overall Progress'):\n",
    "    top_i_features = [feature for feature, importance in sorted(zip(X.columns, RandomForestClassifier(random_state=1).fit(X, y).feature_importances_), key=lambda x: x[1], reverse=True)[:i]]\n",
    "    X_topi = X[top_i_features]\n",
    "    \n",
    "    X_train = X_topi.iloc[:1720]\n",
    "    X_test = X_topi.iloc[1720:]\n",
    "    \n",
    "    y_train = y.iloc[:1720]\n",
    "    y_test = y.iloc[1720:]\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        \n",
    "        # 결과를 리스트에 추가\n",
    "        results.append({'Features': i, 'Model': model_name, 'Precision': precision})\n",
    "\n",
    "# 리스트를 DataFrame으로 변환\n",
    "precision_scores_df = pd.DataFrame(results)\n",
    "\n",
    "# 결과 출력\n",
    "print(precision_scores_df.pivot(index='Features', columns='Model', values='Precision'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.569621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.517790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.491256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.541183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifer</td>\n",
       "      <td>0.519150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.560049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.582621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.514940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.546946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifer</td>\n",
       "      <td>0.522631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.560049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.540562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.521710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.529216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifer</td>\n",
       "      <td>0.541052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.560049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.523442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.517741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.536121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifer</td>\n",
       "      <td>0.531478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.512604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.525016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.520794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.550279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifer</td>\n",
       "      <td>0.549975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.538408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.518690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.522738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.540629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifer</td>\n",
       "      <td>0.539414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>11</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.538408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.506977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.475951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.542686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifer</td>\n",
       "      <td>0.504514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.538408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.508679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.516532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.533813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifer</td>\n",
       "      <td>0.539004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>13</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.538408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.506573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.502489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.529813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifer</td>\n",
       "      <td>0.516104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>14</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.538408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.508130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.520018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.535494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifer</td>\n",
       "      <td>0.518932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>15</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.538301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>15</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.518970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>15</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.532872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>15</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.553086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>15</td>\n",
       "      <td>GradientBoostingClassifer</td>\n",
       "      <td>0.515085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Features                      Model  Precision\n",
       "0          5                        SVC   0.569621\n",
       "1          5         LogisticRegression   0.517790\n",
       "2          5     DecisionTreeClassifier   0.491256\n",
       "3          5     RandomForestClassifier   0.541183\n",
       "4          5  GradientBoostingClassifer   0.519150\n",
       "5          6                        SVC   0.560049\n",
       "6          6         LogisticRegression   0.582621\n",
       "7          6     DecisionTreeClassifier   0.514940\n",
       "8          6     RandomForestClassifier   0.546946\n",
       "9          6  GradientBoostingClassifer   0.522631\n",
       "10         7                        SVC   0.560049\n",
       "11         7         LogisticRegression   0.540562\n",
       "12         7     DecisionTreeClassifier   0.521710\n",
       "13         7     RandomForestClassifier   0.529216\n",
       "14         7  GradientBoostingClassifer   0.541052\n",
       "15         8                        SVC   0.560049\n",
       "16         8         LogisticRegression   0.523442\n",
       "17         8     DecisionTreeClassifier   0.517741\n",
       "18         8     RandomForestClassifier   0.536121\n",
       "19         8  GradientBoostingClassifer   0.531478\n",
       "20         9                        SVC   0.512604\n",
       "21         9         LogisticRegression   0.525016\n",
       "22         9     DecisionTreeClassifier   0.520794\n",
       "23         9     RandomForestClassifier   0.550279\n",
       "24         9  GradientBoostingClassifer   0.549975\n",
       "25        10                        SVC   0.538408\n",
       "26        10         LogisticRegression   0.518690\n",
       "27        10     DecisionTreeClassifier   0.522738\n",
       "28        10     RandomForestClassifier   0.540629\n",
       "29        10  GradientBoostingClassifer   0.539414\n",
       "30        11                        SVC   0.538408\n",
       "31        11         LogisticRegression   0.506977\n",
       "32        11     DecisionTreeClassifier   0.475951\n",
       "33        11     RandomForestClassifier   0.542686\n",
       "34        11  GradientBoostingClassifer   0.504514\n",
       "35        12                        SVC   0.538408\n",
       "36        12         LogisticRegression   0.508679\n",
       "37        12     DecisionTreeClassifier   0.516532\n",
       "38        12     RandomForestClassifier   0.533813\n",
       "39        12  GradientBoostingClassifer   0.539004\n",
       "40        13                        SVC   0.538408\n",
       "41        13         LogisticRegression   0.506573\n",
       "42        13     DecisionTreeClassifier   0.502489\n",
       "43        13     RandomForestClassifier   0.529813\n",
       "44        13  GradientBoostingClassifer   0.516104\n",
       "45        14                        SVC   0.538408\n",
       "46        14         LogisticRegression   0.508130\n",
       "47        14     DecisionTreeClassifier   0.520018\n",
       "48        14     RandomForestClassifier   0.535494\n",
       "49        14  GradientBoostingClassifer   0.518932\n",
       "50        15                        SVC   0.538301\n",
       "51        15         LogisticRegression   0.518970\n",
       "52        15     DecisionTreeClassifier   0.532872\n",
       "53        15     RandomForestClassifier   0.553086\n",
       "54        15  GradientBoostingClassifer   0.515085"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=precision_scores_df.loc[precision_scores_df['Model']=='LogisticRegression',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.517790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.582621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.540562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.523442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.525016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.518690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.506977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.508679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.506573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.508130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.518970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Precision\n",
       "1    0.517790\n",
       "6    0.582621\n",
       "11   0.540562\n",
       "16   0.523442\n",
       "21   0.525016\n",
       "26   0.518690\n",
       "31   0.506977\n",
       "36   0.508679\n",
       "41   0.506573\n",
       "46   0.508130\n",
       "51   0.518970"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[['Precision']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
