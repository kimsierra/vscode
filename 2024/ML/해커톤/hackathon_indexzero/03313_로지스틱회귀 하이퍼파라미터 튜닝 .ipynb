{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best parameters: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Accuracy (LR): 0.5382\n",
      "Precision (LR): 0.5296\n",
      "Recall (LR): 0.5298\n",
      "F1 Score (LR): 0.5296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "60 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1182, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\yeotaekyeong\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.51113026 0.51113026        nan        nan 0.51113026 0.51113026\n",
      "        nan        nan 0.51113026 0.51113026        nan        nan\n",
      " 0.51113026 0.51113026        nan        nan 0.51113026 0.51113026\n",
      "        nan        nan 0.51113026 0.51113026        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from pykrx import stock\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 데이터 로드 및 전처리 (위의 예제와 동일한 방식으로)\n",
    "df = pd.read_csv(\"하이닉스 power (3).csv\", thousands=',', encoding='cp949')\n",
    "df['next_day_return'] = (df['종가'].shift(-1) - df['종가']) / df['종가'] * 100\n",
    "df['target'] = df['next_day_return'].apply(lambda x: 1 if x > 0.25 else 0)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop(['날짜', 'target', 'next_day_return'], axis=1)\n",
    "y = df['target']\n",
    "# Random Forest for feature importance\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "\n",
    "features_rf_sorted = sorted(zip(X.columns, rf.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "features_rf_df = pd.DataFrame(features_rf_sorted, columns=['Feature', 'RF Importance'])\n",
    "\n",
    "# 상관관계가 가장 높은 상위 8개의 피처를 선정\n",
    "top_7_features = [feature for feature, importance in features_rf_sorted[:7]]\n",
    "# X와 y 정의 (df2와 이전 코드에서의 처리 과정을 바탕으로)dp\n",
    "X_top7 = X[top_7_features]\n",
    "y = df['target']  # y 값을 0과 1로 조정\n",
    "\n",
    "# 데이터를 학습 세트와 테스트 세트로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top7, y, test_size=0.25, random_state=66)\n",
    "\n",
    "# 로지스틱 회귀 모델을 위한 하이퍼파라미터 그리드 정의\n",
    "param_grid_lr = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # 규제 강도의 역수\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],  # 사용할 규제\n",
    "    'solver': ['saga']  # 'saga' 솔버는 모든 penalty 옵션 지원\n",
    "}\n",
    "\n",
    "# GridSearchCV 객체 초기화 및 학습\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(max_iter=10000, random_state=1), param_grid_lr, refit=True, verbose=2, cv=5, n_jobs=-1)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터와 모델 출력\n",
    "print(f\"Best parameters: {grid_search_lr.best_params_}\")\n",
    "best_lr_model = grid_search_lr.best_estimator_\n",
    "\n",
    "# 최적의 모델로 테스트 데이터 예측\n",
    "y_pred_lr = best_lr_model.predict(X_test)\n",
    "\n",
    "# 예측 결과에 대한 평가 지표 출력\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr, average='macro')\n",
    "recall_lr = recall_score(y_test, y_pred_lr, average='macro')\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average='macro')\n",
    "\n",
    "print(f\"Accuracy (LR): {accuracy_lr:.4f}\")\n",
    "print(f\"Precision (LR): {precision_lr:.4f}\")\n",
    "print(f\"Recall (LR): {recall_lr:.4f}\")\n",
    "print(f\"F1 Score (LR): {f1_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ParameterGrid, train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "df = pd.read_csv(\"하이닉스 power (3).csv\", thousands=',', encoding='cp949')\n",
    "df['next_day_return'] = (df['종가'].shift(-1) - df['종가']) / df['종가'] * 100\n",
    "df['target'] = df['next_day_return'].apply(lambda x: 1 if x > 0.25 else 0)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop(['날짜', 'target', 'next_day_return'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "# 로지스틱 회귀 모델을 위한 하이퍼파라미터 그리드 정의\n",
    "param_grid_lr = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver': ['saga']\n",
    "}\n",
    "\n",
    "# 평가 함수\n",
    "def evaluate_model(params):\n",
    "    model = LogisticRegression(max_iter=10000, random_state=1, **params)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "# 진행바와 함께 모든 하이퍼파라미터 조합에 대해 평가\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(evaluate_model)(params) for params in tqdm(list(ParameterGrid(param_grid_lr)), desc='Logistic Regression Tuning')\n",
    ")\n",
    "\n",
    "# 최적의 하이퍼파라미터 조합 찾기\n",
    "best_score_idx = np.argmax(results)\n",
    "best_params = list(ParameterGrid(param_grid_lr))[best_score_idx]\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best cross-validation score: {results[best_score_idx]:.4f}\")\n",
    "\n",
    "# 최적의 하이퍼파라미터로 모델 학습\n",
    "best_model = LogisticRegression(max_iter=10000, random_state=1, **best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 모델로 테스트 데이터 예측\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 예측 결과에 대한 평가 지표 출력\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
